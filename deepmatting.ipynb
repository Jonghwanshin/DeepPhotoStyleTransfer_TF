{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Photo Transfer\n",
    "this is the tensorflow version of deep photo transfer \n",
    "deepmatting_seg.lua"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library import for deep photo transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_image_fn = \"\"\n",
    "content_image_fn = \"examples/inputs/seated-nude.jpg\"\n",
    "style_image_fn = \"examples/inputs/tuingen.jpg\"\n",
    "content_seg_fn =  \"\"\n",
    "style_seg_fn = \"\"\n",
    "\n",
    "content_layer =\"\"\n",
    "style_layer = \"\"\n",
    "\n",
    "index = 0;\n",
    "\n",
    "% Local Affine parameters\n",
    "lambda = 1e+4\n",
    "patch = 3\n",
    "eps = 1e-7\n",
    "\n",
    "% reconstruct best local affine using joint bilateral smoothing\n",
    "f_radius = 7\n",
    "f_edge = 0.05\n",
    "\n",
    "% output options\n",
    "print_iter = 1\n",
    "save_iter = 100\n",
    "output_iamge = \"out.png\"\n",
    "index = 1\n",
    "serial = \"serial_example\"\n",
    "\n",
    "% other options\n",
    "%proto_file = 0\n",
    "%model_file = 0\n",
    "%backend\n",
    "%cudnn_autotune\n",
    "seed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Main Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Load\n",
    "- Init, Content and Style Image Load\n",
    "- preprocess image for these images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_image = ndlimage.imread(init_image_fn).astype(float)\n",
    "content_image = ndlimage.imread(content_image_fn).astype(float)\n",
    "style_image = ndlimage.imread(style_image_fn).astype(float)\n",
    "\n",
    "% Setting up c,h,w for each images\n",
    "c,h,w = content_image.size(1), content_image.size(2), content_image.size(3)\n",
    "c2, h2, w2 = style_image.size(1), style_image.size(2), style_image.size(3)\n",
    "\n",
    "% Preprocess image for caffe model\n",
    "init_image_caffe = preprocess(init_image)\n",
    "content_image_caffe = preprocess(content_image)\n",
    "style_image_caffe = preprocess(style_image)\n",
    "\n",
    "% layers\n",
    "content_layers = content_layer.split(\",\")\n",
    "style_layers = style_layer.split(\",\")\n",
    "\n",
    "% preprocess an image before passing it to a Caffe model.\n",
    "% We need to rescale from [0,1] to [0,255] convert from RGB to BGR\n",
    "% and subtract the mean pixel\n",
    "def preprocess(image)\n",
    "% define tensor with torch.DoubleTensor({103.939, 116.77, 123.68})\n",
    "mean_pixel = tf.constant(103.939, 116.77, 123.68)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation Images\n",
    "- load content_segmentation, 3\n",
    "- content segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% get segmentation images\n",
    "content_seg = ndlimage.imread(content_seg_fn)\n",
    "content_seg = tf.image.resize_images(content_seg, [h,w], ResizeMethod.BILINEAR)\n",
    "style_seg = ndlimage.imread(style_seg_fn)\n",
    "style_seg = tf.image.resize_images(style_seg, [h2,w2], ResizeMethod.BILINEAR)\n",
    "\n",
    "% define color codes\n",
    "color_codes = {'blue', 'green', 'black', 'white', 'red', 'yellow', 'grey', 'lightblue', 'purple'}\n",
    "color_content_masks, color_style_masks = {}, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    # Input data\n",
    "    \n",
    "    # Variables\n",
    "    \n",
    "    # Model\n",
    "    \n",
    "    # Training computation\n",
    "    logits = model(tf_train_dataset)\n",
    "    loss = tf.reduce_mean() #style loss + content loss\n",
    "    \n",
    "    # Predictions for the training, validation and test data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run\n",
    "    print('Initialized')\n",
    "    for step in range(num_iter)\n",
    "      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
